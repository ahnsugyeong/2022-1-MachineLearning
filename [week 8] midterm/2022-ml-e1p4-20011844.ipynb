{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-04T04:14:02.621103Z","iopub.execute_input":"2022-05-04T04:14:02.621438Z","iopub.status.idle":"2022-05-04T04:14:02.634776Z","shell.execute_reply.started":"2022-05-04T04:14:02.621402Z","shell.execute_reply":"2022-05-04T04:14:02.634125Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"import random\nimport os\nseed = 42\nrandom.seed(seed)\nnp.random.seed(seed)\nos.environ[\"PYTHONHASHSEED\"] = str(seed)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T04:14:02.639460Z","iopub.execute_input":"2022-05-04T04:14:02.640192Z","iopub.status.idle":"2022-05-04T04:14:02.649850Z","shell.execute_reply.started":"2022-05-04T04:14:02.640127Z","shell.execute_reply":"2022-05-04T04:14:02.648861Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"sample = pd.read_csv('../input/2022-ml-midterm-p4/sample.csv')\ntest = pd.read_csv('../input/2022-ml-midterm-p4/test.csv')\ntrain = pd.read_csv('../input/2022-ml-midterm-p4/train.csv')","metadata":{"execution":{"iopub.status.busy":"2022-05-04T04:14:02.662042Z","iopub.execute_input":"2022-05-04T04:14:02.662440Z","iopub.status.idle":"2022-05-04T04:14:02.752180Z","shell.execute_reply.started":"2022-05-04T04:14:02.662404Z","shell.execute_reply":"2022-05-04T04:14:02.751254Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"train.head()\ntrainX = train.drop(['price', 'ID'], axis = 1)\ntrainY = train['price']\ntest = test.drop(['ID'], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T04:14:02.753960Z","iopub.execute_input":"2022-05-04T04:14:02.754229Z","iopub.status.idle":"2022-05-04T04:14:02.763462Z","shell.execute_reply.started":"2022-05-04T04:14:02.754196Z","shell.execute_reply":"2022-05-04T04:14:02.762598Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"trainX.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-04T04:14:02.764883Z","iopub.execute_input":"2022-05-04T04:14:02.765138Z","iopub.status.idle":"2022-05-04T04:14:02.785980Z","shell.execute_reply.started":"2022-05-04T04:14:02.765106Z","shell.execute_reply":"2022-05-04T04:14:02.785173Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"print(type(test['model']))\n\nfrom sklearn import preprocessing\nle = preprocessing.LabelEncoder()\n\na = pd.concat([trainX['model'], test['model']])\nle.fit(a)\ntrainX['model'] = le.transform(trainX['model'])\ntest['model'] = le.transform(test['model'])\ntrainX.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-04T04:14:02.787966Z","iopub.execute_input":"2022-05-04T04:14:02.788446Z","iopub.status.idle":"2022-05-04T04:14:02.824140Z","shell.execute_reply.started":"2022-05-04T04:14:02.788412Z","shell.execute_reply":"2022-05-04T04:14:02.823285Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import RobustScaler\nscaler = RobustScaler()\ntrainX_sc = scaler.fit_transform(trainX)\ntest_sc = scaler.transform(test)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T04:14:02.825252Z","iopub.execute_input":"2022-05-04T04:14:02.825482Z","iopub.status.idle":"2022-05-04T04:14:02.854450Z","shell.execute_reply.started":"2022-05-04T04:14:02.825447Z","shell.execute_reply":"2022-05-04T04:14:02.853675Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# from sklearn.model_selection import train_test_split\n# X_train, X_test, y_train, y_test = train_test_split(trainX_sc, trainY, test_size=0.33, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T04:14:02.855434Z","iopub.execute_input":"2022-05-04T04:14:02.855850Z","iopub.status.idle":"2022-05-04T04:14:02.859624Z","shell.execute_reply.started":"2022-05-04T04:14:02.855815Z","shell.execute_reply":"2022-05-04T04:14:02.858795Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# from sklearn.neighbors import KNeighborsRegressor\n# # knn regressor 호출\n# neigh = KNeighborsRegressor(n_neighbors=7,  p = 1, weights = 'distance')\n# # 학습시키기\n# neigh.fit(trainX_sc, trainY)\n# #print(neigh.score(X_test, y_test))\n# #예측하기\n# pred = neigh.predict(test_sc)\n\nfrom sklearn.ensemble import RandomForestRegressor\nregr = RandomForestRegressor(max_depth=2, random_state=42)\nregr.fit(trainX_sc, trainY)\npred = regr.predict(test_sc)\n\n\n# from sklearn.linear_model import LogisticRegression\n# logis = LogisticRegression()\n# logis.fit(trainX_sc, trainY)\n# pred = logis.predict(test_sc)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T04:14:02.861445Z","iopub.execute_input":"2022-05-04T04:14:02.861698Z","iopub.status.idle":"2022-05-04T04:14:04.705940Z","shell.execute_reply.started":"2022-05-04T04:14:02.861668Z","shell.execute_reply":"2022-05-04T04:14:04.705088Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"sample['price'] = pred\nsample.to_csv('submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T04:14:04.707076Z","iopub.execute_input":"2022-05-04T04:14:04.707351Z","iopub.status.idle":"2022-05-04T04:14:04.778053Z","shell.execute_reply.started":"2022-05-04T04:14:04.707323Z","shell.execute_reply":"2022-05-04T04:14:04.777368Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"# Review\n\n1. label encoder로 'model'의 값을 labeling 해주었다.\n    이 때, train data에 나오지 않은 값이 test data에 있었기 때문에\n    두 데이터를 concat을 이용하여 합친 다음 fit을 해주고, 각각\n    transform 해주었다.\n    \n2. train_test_split하지 않은 데이터로 학습시킨 모델의 성능이 더 우수했다.\n3. KNeighborsRegressor(n_neighbors=7,  p = 1, weights = 'distance')로 1863.48313의 성능을 보였다.\n4. RandomForestRegressor(max_depth=2, random_state=42)는 4472.12168의 끔찍한 성능을 보였다..\n\n**❓ LogisticRegression은 회귀에 사용할 수 있는 방법론이 아닌가요? 🙀 \n➡️ YES!!! LogisticRegression은 결과가 범주형일 때 사용**\n","metadata":{}}]}